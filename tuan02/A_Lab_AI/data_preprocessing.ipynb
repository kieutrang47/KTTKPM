{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d41ec73-c8a3-4949-8d4d-c25632509300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.13/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt numpy\n",
    "!pip install numpy\n",
    "\n",
    "# Cài đặt pandas\n",
    "!pip install pandas\n",
    "\n",
    "# Nếu muốn test thử có thể cài thêm matplotlib để visualize (không bắt buộc)\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b66a80b-cf63-4120-ad88-0d91b5204b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.1.3\n",
      "Pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a916ffbb-021f-4a6e-af79-cd7a9161484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã import thư viện!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Cấu hình hiển thị pandas cho dễ nhìn\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Đã import thư viện!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23225139-3063-44d4-9a03-2aab272fa5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chuẩn hóa (Scaling)\n",
    "class Normalizer:\n",
    "    \"\"\"Chuẩn hóa dữ liệu về khoảng [0, 1] (Min-Max Scaling)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.min_vals = None\n",
    "        self.max_vals = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"Tính min và max của từng cột\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "            \n",
    "        # Lưu min, max của từng cột\n",
    "        self.min_vals = np.min(X, axis=0)\n",
    "        self.max_vals = np.max(X, axis=0)\n",
    "        \n",
    "        # Tránh chia cho 0 (nếu min = max)\n",
    "        for i in range(len(self.max_vals)):\n",
    "            if self.max_vals[i] == self.min_vals[i]:\n",
    "                self.max_vals[i] = 1\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Áp dụng công thức: (x - min) / (max - min)\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_np = X.values.copy()\n",
    "            is_dataframe = True\n",
    "        else:\n",
    "            X_np = X.copy()\n",
    "            is_dataframe = False\n",
    "            \n",
    "        # Kiểm tra đã fit chưa\n",
    "        if self.min_vals is None or self.max_vals is None:\n",
    "            raise ValueError(\"Cần gọi fit() trước khi transform()\")\n",
    "            \n",
    "        # Áp dụng normalization\n",
    "        for i in range(X_np.shape[1]):\n",
    "            denominator = self.max_vals[i] - self.min_vals[i]\n",
    "            if denominator != 0:\n",
    "                X_np[:, i] = (X_np[:, i] - self.min_vals[i]) / denominator\n",
    "            else:\n",
    "                X_np[:, i] = 0\n",
    "                \n",
    "        # Trả về định dạng ban đầu\n",
    "        if is_dataframe:\n",
    "            return pd.DataFrame(X_np, columns=X.columns)\n",
    "        return X_np\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Gộp fit và transform\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X) \n",
    "\n",
    "class StandardScaler:\n",
    "    \"\"\"Chuẩn hóa dữ liệu về mean=0, std=1 (Z-Score Scaling)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean_vals = None\n",
    "        self.std_vals = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"Tính mean và std của từng cột\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "            \n",
    "        self.mean_vals = np.mean(X, axis=0)\n",
    "        self.std_vals = np.std(X, axis=0)\n",
    "        \n",
    "        # Tránh chia cho 0\n",
    "        for i in range(len(self.std_vals)):\n",
    "            if self.std_vals[i] == 0:\n",
    "                self.std_vals[i] = 1\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Áp dụng công thức: (x - mean) / std\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_np = X.values.copy()\n",
    "            is_dataframe = True\n",
    "        else:\n",
    "            X_np = X.copy()\n",
    "            is_dataframe = False\n",
    "            \n",
    "        if self.mean_vals is None or self.std_vals is None:\n",
    "            raise ValueError(\"Cần gọi fit() trước khi transform()\")\n",
    "            \n",
    "        # Áp dụng standardization\n",
    "        for i in range(X_np.shape[1]):\n",
    "            if self.std_vals[i] != 0:\n",
    "                X_np[:, i] = (X_np[:, i] - self.mean_vals[i]) / self.std_vals[i]\n",
    "            else:\n",
    "                X_np[:, i] = 0\n",
    "                \n",
    "        if is_dataframe:\n",
    "            return pd.DataFrame(X_np, columns=X.columns)\n",
    "        return X_np\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Gộp fit và transform\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee4f7c18-3dd6-4f62-8b85-8551688cf0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "    \"\"\"Chuẩn hóa dữ liệu về mean=0, std=1\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean_vals = None\n",
    "        self.std_vals = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"Tính mean và std của từng cột\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "            \n",
    "        self.mean_vals = np.mean(X, axis=0)\n",
    "        self.std_vals = np.std(X, axis=0)\n",
    "        \n",
    "        # Tránh chia cho 0\n",
    "        for i in range(len(self.std_vals)):\n",
    "            if self.std_vals[i] == 0:\n",
    "                self.std_vals[i] = 1\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Áp dụng công thức: (x - mean) / std\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X_np = X.values.copy()\n",
    "            is_dataframe = True\n",
    "        else:\n",
    "            X_np = X.copy()\n",
    "            is_dataframe = False\n",
    "            \n",
    "        if self.mean_vals is None or self.std_vals is None:\n",
    "            raise ValueError(\"Cần gọi fit() trước khi transform()\")\n",
    "            \n",
    "        # Áp dụng standardization\n",
    "        for i in range(X_np.shape[1]):\n",
    "            if self.std_vals[i] != 0:\n",
    "                X_np[:, i] = (X_np[:, i] - self.mean_vals[i]) / self.std_vals[i]\n",
    "            else:\n",
    "                X_np[:, i] = 0\n",
    "                \n",
    "        if is_dataframe:\n",
    "            return pd.DataFrame(X_np, columns=X.columns)\n",
    "        return X_np\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Gộp fit và transform\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe2c3b8d-a4e8-448c-af35-59881ba1654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValueHandler:\n",
    "    \"\"\"Xử lý giá trị thiếu (Shipper dọn rác)\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_missing(df):\n",
    "        return df.isnull()\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_missing(df):\n",
    "        return df.isnull().sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def fill_mean(df, columns=None):\n",
    "        \"\"\"Điền missing bằng giá trị trung bình\"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        if columns is None:\n",
    "            columns = df_copy.select_dtypes(include=[np.number]).columns\n",
    "            \n",
    "        for col in columns:\n",
    "            if col in df_copy.columns:\n",
    "                mean_val = df_copy[col].mean()\n",
    "                # ✅ ĐÃ FIX: Gán trực tiếp, ko dùng inplace=True\n",
    "                df_copy[col] = df_copy[col].fillna(mean_val)\n",
    "                \n",
    "        return df_copy\n",
    "    \n",
    "    @staticmethod\n",
    "    def fill_median(df, columns=None):\n",
    "        \"\"\"Điền missing bằng giá trị trung vị\"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        if columns is None:\n",
    "            columns = df_copy.select_dtypes(include=[np.number]).columns\n",
    "            \n",
    "        for col in columns:\n",
    "            if col in df_copy.columns:\n",
    "                median_val = df_copy[col].median()\n",
    "                # ✅ ĐÃ FIX\n",
    "                df_copy[col] = df_copy[col].fillna(median_val)\n",
    "                \n",
    "        return df_copy\n",
    "    \n",
    "    @staticmethod\n",
    "    def fill_mode(df, columns=None):\n",
    "        \"\"\"Điền missing bằng giá trị xuất hiện nhiều nhất\"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        if columns is None:\n",
    "            columns = df_copy.columns\n",
    "            \n",
    "        for col in columns:\n",
    "            if col in df_copy.columns:\n",
    "                mode_vals = df_copy[col].mode()\n",
    "                if not mode_vals.empty:\n",
    "                    # ✅ ĐÃ FIX\n",
    "                    df_copy[col] = df_copy[col].fillna(mode_vals[0])\n",
    "                    \n",
    "        return df_copy\n",
    "    \n",
    "    @staticmethod\n",
    "    def fill_value(df, value, columns=None):\n",
    "        \"\"\"Điền missing bằng giá trị cố định\"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        if columns is None:\n",
    "            columns = df_copy.columns\n",
    "            \n",
    "        for col in columns:\n",
    "            if col in df_copy.columns:\n",
    "                # ✅ ĐÃ FIX\n",
    "                df_copy[col] = df_copy[col].fillna(value)\n",
    "                \n",
    "        return df_copy\n",
    "    \n",
    "    @staticmethod\n",
    "    def drop_rows(df, thresh=None):\n",
    "        if thresh is None:\n",
    "            return df.dropna()\n",
    "        else:\n",
    "            return df.dropna(thresh=thresh)\n",
    "    \n",
    "    @staticmethod\n",
    "    def drop_columns(df, threshold=0.5):\n",
    "        missing_ratio = df.isnull().sum() / len(df)\n",
    "        cols_to_drop = missing_ratio[missing_ratio > threshold].index\n",
    "        return df.drop(columns=cols_to_drop)\n",
    "\n",
    "class CategoricalEncoder:\n",
    "    \"\"\"Mã hóa biến phân loại (Phiên dịch viên)\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def one_hot_encode(df, columns=None, drop_first=False):\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        if columns is None:\n",
    "            cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns\n",
    "        else:\n",
    "            cat_cols = columns\n",
    "            \n",
    "        num_cols = [col for col in df_copy.columns if col not in cat_cols]\n",
    "        result_dfs = []\n",
    "        \n",
    "        if num_cols:\n",
    "            result_dfs.append(df_copy[num_cols])\n",
    "            \n",
    "        for col in cat_cols:\n",
    "            if col in df_copy.columns:\n",
    "                unique_vals = df_copy[col].dropna().unique()\n",
    "                for val in unique_vals:\n",
    "                    new_col_name = f\"{col}_{val}\"\n",
    "                    new_col_data = (df_copy[col] == val).astype(int)\n",
    "                    result_dfs.append(pd.DataFrame({new_col_name: new_col_data}))\n",
    "        \n",
    "        result = pd.concat(result_dfs, axis=1)\n",
    "        \n",
    "        if drop_first and len(cat_cols) > 0:\n",
    "             # Logic drop first đơn giản hóa\n",
    "             pass\n",
    "                    \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def label_encode(df, columns=None):\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        if columns is None:\n",
    "            cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns\n",
    "        else:\n",
    "            cat_cols = columns\n",
    "            \n",
    "        encoding_maps = {}\n",
    "        \n",
    "        for col in cat_cols:\n",
    "            if col in df_copy.columns:\n",
    "                unique_vals = df_copy[col].dropna().unique()\n",
    "                encoding_map = {val: i for i, val in enumerate(unique_vals)}\n",
    "                df_copy[col] = df_copy[col].map(encoding_map)\n",
    "                encoding_maps[col] = encoding_map\n",
    "                \n",
    "        return df_copy, encoding_maps\n",
    "    \n",
    "    @staticmethod\n",
    "    def frequency_encode(df, columns=None):\n",
    "        df_copy = df.copy()\n",
    "        if columns is None:\n",
    "            cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns\n",
    "        else:\n",
    "            cat_cols = columns\n",
    "            \n",
    "        for col in cat_cols:\n",
    "            if col in df_copy.columns:\n",
    "                freq = df_copy[col].value_counts(normalize=True)\n",
    "                df_copy[col] = df_copy[col].map(freq)\n",
    "                \n",
    "        return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4730160e-c489-4a16-851e-c2102d7be027",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalEncoder:\n",
    "    \"\"\"Mã hóa biến phân loại\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def one_hot_encode(df, columns=None, drop_first=False):\n",
    "        \"\"\"\n",
    "        One-hot encoding\n",
    "        drop_first: có bỏ cột đầu tiên không (tránh multicollinearity)\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        if columns is None:\n",
    "            # Tự động tìm cột categorical\n",
    "            cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns\n",
    "        else:\n",
    "            cat_cols = columns\n",
    "            \n",
    "        # Lưu các cột số để giữ lại\n",
    "        num_cols = [col for col in df_copy.columns if col not in cat_cols]\n",
    "        result_dfs = []\n",
    "        \n",
    "        # Thêm cột số trước\n",
    "        if num_cols:\n",
    "            result_dfs.append(df_copy[num_cols])\n",
    "            \n",
    "        # Xử lý từng cột categorical\n",
    "        for col in cat_cols:\n",
    "            if col in df_copy.columns:\n",
    "                unique_vals = df_copy[col].dropna().unique()\n",
    "                \n",
    "                # Tạo cột mới cho mỗi giá trị unique\n",
    "                for val in unique_vals:\n",
    "                    new_col_name = f\"{col}_{val}\"\n",
    "                    new_col_data = (df_copy[col] == val).astype(int)\n",
    "                    result_dfs.append(pd.DataFrame({new_col_name: new_col_data}))\n",
    "        \n",
    "        # Ghép tất cả lại\n",
    "        result = pd.concat(result_dfs, axis=1)\n",
    "        \n",
    "        # Bỏ cột đầu nếu cần\n",
    "        if drop_first and cat_cols.any():\n",
    "            for col in cat_cols:\n",
    "                if f\"{col}_{df_copy[col].iloc[0]}\" in result.columns:\n",
    "                    result = result.drop(f\"{col}_{df_copy[col].iloc[0]}\", axis=1)\n",
    "                    \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def label_encode(df, columns=None):\n",
    "        \"\"\"\n",
    "        Label encoding - gán số cho mỗi giá trị unique\n",
    "        Trả về DataFrame đã encode và mapping dictionary\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        if columns is None:\n",
    "            cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns\n",
    "        else:\n",
    "            cat_cols = columns\n",
    "            \n",
    "        encoding_maps = {}\n",
    "        \n",
    "        for col in cat_cols:\n",
    "            if col in df_copy.columns:\n",
    "                # Tạo mapping từ giá trị sang số\n",
    "                unique_vals = df_copy[col].dropna().unique()\n",
    "                encoding_map = {val: i for i, val in enumerate(unique_vals)}\n",
    "                \n",
    "                # Áp dụng mapping\n",
    "                df_copy[col] = df_copy[col].map(encoding_map)\n",
    "                encoding_maps[col] = encoding_map\n",
    "                \n",
    "        return df_copy, encoding_maps\n",
    "    \n",
    "    @staticmethod\n",
    "    def frequency_encode(df, columns=None):\n",
    "        \"\"\"\n",
    "        Frequency encoding - thay thế bằng tần suất xuất hiện\n",
    "        \"\"\"\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        if columns is None:\n",
    "            cat_cols = df_copy.select_dtypes(include=['object', 'category']).columns\n",
    "        else:\n",
    "            cat_cols = columns\n",
    "            \n",
    "        for col in cat_cols:\n",
    "            if col in df_copy.columns:\n",
    "                # Tính tần suất\n",
    "                freq = df_copy[col].value_counts(normalize=True)\n",
    "                \n",
    "                # Thay thế bằng tần suất\n",
    "                df_copy[col] = df_copy[col].map(freq)\n",
    "                \n",
    "        return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0ba89a7-dae6-4574-b536-fa57d2fb1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2, random_state=None, shuffle=True):\n",
    "    \"\"\"Chia dữ liệu thành tập train và test\"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_np = X.values\n",
    "    else:\n",
    "        X_np = X.copy()\n",
    "        \n",
    "    if isinstance(y, pd.Series):\n",
    "        y_np = y.values\n",
    "    else:\n",
    "        y_np = y.copy()\n",
    "    \n",
    "    if len(X_np) != len(y_np):\n",
    "        raise ValueError(\"X và y phải có cùng số lượng mẫu\")\n",
    "    \n",
    "    n_samples = len(X_np)\n",
    "    n_test = int(n_samples * test_size)\n",
    "    n_train = n_samples - n_test\n",
    "    \n",
    "    indices = np.arange(n_samples)\n",
    "    \n",
    "    if shuffle:\n",
    "        if random_state is not None:\n",
    "            np.random.seed(random_state)\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    train_indices = indices[:n_train]\n",
    "    test_indices = indices[n_train:]\n",
    "    \n",
    "    X_train = X_np[train_indices]\n",
    "    X_test = X_np[test_indices]\n",
    "    y_train = y_np[train_indices]\n",
    "    y_test = y_np[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def kfold_split(X, y, n_splits=5, random_state=None, shuffle=True):\n",
    "    \"\"\"Chia dữ liệu cho K-Fold Cross Validation\"\"\"\n",
    "    # (Đã lược bớt phần convert type để code ngắn gọn, logic giữ nguyên)\n",
    "    if isinstance(X, pd.DataFrame): X_np = X.values\n",
    "    else: X_np = X.copy()\n",
    "    \n",
    "    if isinstance(y, pd.Series): y_np = y.values\n",
    "    else: y_np = y.copy()\n",
    "    \n",
    "    n_samples = len(X_np)\n",
    "    indices = np.arange(n_samples)\n",
    "    \n",
    "    if shuffle:\n",
    "        if random_state is not None: np.random.seed(random_state)\n",
    "        np.random.shuffle(indices)\n",
    "    \n",
    "    fold_size = n_samples // n_splits\n",
    "    folds = []\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        test_start = i * fold_size\n",
    "        test_end = test_start + fold_size if i < n_splits - 1 else n_samples\n",
    "        \n",
    "        test_mask = np.zeros(n_samples, dtype=bool)\n",
    "        test_mask[test_start:test_end] = True\n",
    "        train_mask = ~test_mask\n",
    "        \n",
    "        X_train = X_np[train_mask]\n",
    "        X_test = X_np[test_mask]\n",
    "        y_train = y_np[train_mask]\n",
    "        y_test = y_np[test_mask]\n",
    "        \n",
    "        folds.append((X_train, X_test, y_train, y_test))\n",
    "    \n",
    "    return folds\n",
    "\n",
    "def describe_data(df):\n",
    "    \"\"\"Mô tả dữ liệu chi tiết\"\"\"\n",
    "    print(\"=== THÔNG TIN DỮ LIỆU ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    print(f\"\\nMissing Values:\\n{df.isnull().sum()}\")\n",
    "    print(f\"\\nSummary Statistics:\\n{df.describe()}\")\n",
    "    return {'shape': df.shape}\n",
    "\n",
    "def get_correlation(df):\n",
    "    \"\"\"Tính ma trận tương quan\"\"\"\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    if numeric_df.empty: return None\n",
    "    return numeric_df.corr()\n",
    "\n",
    "def detect_outliers(df, method='iqr', threshold=1.5):\n",
    "    \"\"\"Phát hiện outliers\"\"\"\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    if numeric_df.empty: return pd.DataFrame()\n",
    "    \n",
    "    outliers_info = {}\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        for col in numeric_df.columns:\n",
    "            Q1 = numeric_df[col].quantile(0.25)\n",
    "            Q3 = numeric_df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            outliers = numeric_df[(numeric_df[col] < (Q1 - threshold * IQR)) | \n",
    "                                  (numeric_df[col] > (Q3 + threshold * IQR))]\n",
    "            outliers_info[col] = len(outliers)\n",
    "            \n",
    "    elif method == 'zscore':\n",
    "        for col in numeric_df.columns:\n",
    "            mean_val = numeric_df[col].mean()\n",
    "            std_val = numeric_df[col].std()\n",
    "            if std_val > 0:\n",
    "                z_scores = np.abs((numeric_df[col] - mean_val) / std_val)\n",
    "                outliers = numeric_df[z_scores > threshold]\n",
    "                outliers_info[col] = len(outliers)\n",
    "    \n",
    "    return pd.DataFrame.from_dict(outliers_info, orient='index', columns=['outlier_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dabd703-6a37-4070-98f1-dadf91d26b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_data(df):\n",
    "    \"\"\"Mô tả dữ liệu chi tiết\"\"\"\n",
    "    print(\"=== THÔNG TIN DỮ LIỆU ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    print(f\"\\nData Types:\")\n",
    "    print(df.dtypes)\n",
    "    print(f\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(f\"\\nSummary Statistics:\")\n",
    "    print(df.describe())\n",
    "    print(f\"\\nMemory Usage: {df.memory_usage().sum() / 1024:.2f} KB\")\n",
    "    \n",
    "    return {\n",
    "        'shape': df.shape,\n",
    "        'columns': list(df.columns),\n",
    "        'missing': df.isnull().sum().to_dict(),\n",
    "        'dtypes': df.dtypes.to_dict()\n",
    "    }\n",
    "\n",
    "\n",
    "def get_correlation(df):\n",
    "    \"\"\"Tính ma trận tương quan\"\"\"\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    if numeric_df.empty:\n",
    "        print(\"Không có cột số để tính correlation\")\n",
    "        return None\n",
    "    \n",
    "    corr_matrix = numeric_df.corr()\n",
    "    return corr_matrix\n",
    "\n",
    "\n",
    "def detect_outliers(df, method='iqr', threshold=1.5):\n",
    "    \"\"\"\n",
    "    Phát hiện outliers\n",
    "    method: 'iqr' hoặc 'zscore'\n",
    "    \"\"\"\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    if numeric_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    outliers_info = {}\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        # IQR method\n",
    "        for col in numeric_df.columns:\n",
    "            Q1 = numeric_df[col].quantile(0.25)\n",
    "            Q3 = numeric_df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "            \n",
    "            outliers = numeric_df[(numeric_df[col] < lower_bound) | \n",
    "                                  (numeric_df[col] > upper_bound)]\n",
    "            outliers_info[col] = len(outliers)\n",
    "            \n",
    "    elif method == 'zscore':\n",
    "        # Z-score method\n",
    "        for col in numeric_df.columns:\n",
    "            mean_val = numeric_df[col].mean()\n",
    "            std_val = numeric_df[col].std()\n",
    "            \n",
    "            if std_val > 0:\n",
    "                z_scores = np.abs((numeric_df[col] - mean_val) / std_val)\n",
    "                outliers = numeric_df[z_scores > threshold]\n",
    "                outliers_info[col] = len(outliers)\n",
    "    \n",
    "    return pd.DataFrame.from_dict(outliers_info, orient='index', columns=['outlier_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b42bc44-e668-4735-a23d-18bdeea41154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline:\n",
    "    \"\"\"Pipeline xử lý dữ liệu từ đầu đến cuối\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = None\n",
    "        self.encoder = None\n",
    "        self.encoding_maps = {}\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def fit(self, X, y=None, \n",
    "            normalize=True, scale_method='standard',\n",
    "            handle_missing=True, missing_strategy='mean',\n",
    "            encode_categorical=True, encode_method='label'):\n",
    "        \n",
    "        X_processed = X.copy()\n",
    "        \n",
    "        # 1. Xử lý missing values\n",
    "        if handle_missing:\n",
    "            if missing_strategy == 'mean':\n",
    "                X_processed = MissingValueHandler.fill_mean(X_processed)\n",
    "            elif missing_strategy == 'median':\n",
    "                X_processed = MissingValueHandler.fill_median(X_processed)\n",
    "            elif missing_strategy == 'mode':\n",
    "                X_processed = MissingValueHandler.fill_mode(X_processed)\n",
    "        \n",
    "        # 2. Encode categorical\n",
    "        if encode_categorical:\n",
    "            if encode_method == 'label':\n",
    "                X_processed, self.encoding_maps = CategoricalEncoder.label_encode(X_processed)\n",
    "            elif encode_method == 'one_hot':\n",
    "                X_processed = CategoricalEncoder.one_hot_encode(X_processed)\n",
    "        \n",
    "        self.feature_names = list(X_processed.columns)\n",
    "        \n",
    "        # 3. Chuẩn hóa dữ liệu (Lưu ý: Chỉ fit scaler trên tập train!)\n",
    "        if normalize:\n",
    "            if scale_method == 'standard':\n",
    "                self.scaler = StandardScaler()\n",
    "                X_processed = self.scaler.fit_transform(X_processed)\n",
    "            elif scale_method == 'minmax':\n",
    "                self.scaler = Normalizer()\n",
    "                X_processed = self.scaler.fit_transform(X_processed)\n",
    "        \n",
    "        return X_processed\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Áp dụng transformations đã fit (Dùng cho tập Test)\"\"\"\n",
    "        X_processed = X.copy()\n",
    "        \n",
    "        # 1. Xử lý missing\n",
    "        if hasattr(self, 'missing_strategy'): # (Giả định đơn giản, thực tế cần lưu strategy)\n",
    "            X_processed = MissingValueHandler.fill_mean(X_processed)\n",
    "        \n",
    "        # 2. Encode categorical (Dùng map đã học)\n",
    "        if self.encoding_maps:\n",
    "            for col, mapping in self.encoding_maps.items():\n",
    "                if col in X_processed.columns:\n",
    "                    # Map giá trị, nếu ko thấy thì điền NaN hoặc xử lý riêng\n",
    "                    X_processed[col] = X_processed[col].map(mapping)\n",
    "                    # Fill NaN sinh ra do giá trị lạ trong tập test (nếu cần)\n",
    "                    X_processed[col] = X_processed[col].fillna(-1) \n",
    "        \n",
    "        # 3. Chuẩn hóa (Dùng scaler đã học từ train)\n",
    "        if self.scaler:\n",
    "            X_processed = self.scaler.transform(X_processed)\n",
    "        \n",
    "        return X_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5009307c-3daa-4289-ad03-8e3ef6c4fde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KIỂM TRA THƯ VIỆN XỬ LÝ DỮ LIỆU ===\n",
      "1. Dữ liệu gốc:\n",
      "    age   salary  experience department education\n",
      "0  25.0  30000.0           1         IT  Bachelor\n",
      "1  30.0  35000.0           2         HR    Master\n",
      "2   NaN  40000.0           3         IT  Bachelor\n",
      "3  35.0      NaN           4    Finance       PhD\n",
      "4  40.0  50000.0           5         HR    Master\n",
      "5  45.0  55000.0           6         IT  Bachelor\n",
      "6  50.0  60000.0           7    Finance       PhD\n",
      "7  55.0  65000.0           8         HR    Master\n",
      "8  60.0  70000.0           9         IT  Bachelor\n",
      "9  65.0  75000.0          10    Finance       PhD\n",
      "\n",
      "2. Thông tin missing:\n",
      "age           1\n",
      "salary        1\n",
      "experience    0\n",
      "department    0\n",
      "education     0\n",
      "dtype: int64\n",
      "\n",
      "3. Sau khi fill missing với mean:\n",
      "    age        salary  experience department education\n",
      "0  25.0  30000.000000           1         IT  Bachelor\n",
      "1  30.0  35000.000000           2         HR    Master\n",
      "2  45.0  40000.000000           3         IT  Bachelor\n",
      "3  35.0  53333.333333           4    Finance       PhD\n",
      "4  40.0  50000.000000           5         HR    Master\n",
      "5  45.0  55000.000000           6         IT  Bachelor\n",
      "6  50.0  60000.000000           7    Finance       PhD\n",
      "7  55.0  65000.000000           8         HR    Master\n",
      "8  60.0  70000.000000           9         IT  Bachelor\n",
      "9  65.0  75000.000000          10    Finance       PhD\n",
      "\n",
      "4. Sau khi label encode:\n",
      "    age        salary  experience  department  education\n",
      "0  25.0  30000.000000           1           0          0\n",
      "1  30.0  35000.000000           2           1          1\n",
      "2  45.0  40000.000000           3           0          0\n",
      "3  35.0  53333.333333           4           2          2\n",
      "4  40.0  50000.000000           5           1          1\n",
      "5  45.0  55000.000000           6           0          0\n",
      "6  50.0  60000.000000           7           2          2\n",
      "7  55.0  65000.000000           8           1          1\n",
      "8  60.0  70000.000000           9           0          0\n",
      "9  65.0  75000.000000          10           2          2\n",
      "Mapping: {'department': {'IT': 0, 'HR': 1, 'Finance': 2}, 'education': {'Bachelor': 0, 'Master': 1, 'PhD': 2}}\n",
      "\n",
      "5. Sau khi standard scaling:\n",
      "        age    salary  experience\n",
      "0 -1.632993 -1.649916   -1.566699\n",
      "1 -1.224745 -1.296362   -1.218544\n",
      "2  0.000000 -0.942809   -0.870388\n",
      "3 -0.816497  0.000000   -0.522233\n",
      "4 -0.408248 -0.235702   -0.174078\n",
      "5  0.000000  0.117851    0.174078\n",
      "6  0.408248  0.471405    0.522233\n",
      "7  0.816497  0.824958    0.870388\n",
      "8  1.224745  1.178511    1.218544\n",
      "9  1.632993  1.532065    1.566699\n",
      "\n",
      "6. Kết quả split:\n",
      "X_train shape: (7, 3)\n",
      "X_test shape: (3, 3)\n",
      "\n",
      "7. Kết quả pipeline:\n",
      "        age    salary  experience  department  education\n",
      "0 -1.632993 -1.649916   -1.566699   -1.083473  -1.083473\n",
      "1 -1.224745 -1.296362   -1.218544    0.120386   0.120386\n",
      "2  0.000000 -0.942809   -0.870388   -1.083473  -1.083473\n",
      "3 -0.816497  0.000000   -0.522233    1.324244   1.324244\n",
      "4 -0.408248 -0.235702   -0.174078    0.120386   0.120386\n",
      "\n",
      "KIỂM TRA HOÀN TẤT!\n"
     ]
    }
   ],
   "source": [
    "def test_library():\n",
    "    \"\"\"Hàm test thư viện\"\"\"\n",
    "    print(\"=== KIỂM TRA THƯ VIỆN XỬ LÝ DỮ LIỆU ===\")\n",
    "    \n",
    "    # Tạo dữ liệu mẫu\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    data = {\n",
    "        'age': [25, 30, np.nan, 35, 40, 45, 50, 55, 60, 65],\n",
    "        'salary': [30000, 35000, 40000, np.nan, 50000, 55000, 60000, 65000, 70000, 75000],\n",
    "        'experience': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'department': ['IT', 'HR', 'IT', 'Finance', 'HR', 'IT', 'Finance', 'HR', 'IT', 'Finance'],\n",
    "        'education': ['Bachelor', 'Master', 'Bachelor', 'PhD', 'Master', \n",
    "                      'Bachelor', 'PhD', 'Master', 'Bachelor', 'PhD']\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"1. Dữ liệu gốc:\")\n",
    "    print(df)\n",
    "    print(\"\\n2. Thông tin missing:\")\n",
    "    print(MissingValueHandler.count_missing(df))\n",
    "    \n",
    "    # Test xử lý missing values\n",
    "    df_filled = MissingValueHandler.fill_mean(df, ['age', 'salary'])\n",
    "    print(\"\\n3. Sau khi fill missing với mean:\")\n",
    "    print(df_filled)\n",
    "    \n",
    "    # Test encode categorical\n",
    "    df_encoded, mapping = CategoricalEncoder.label_encode(df_filled, ['department', 'education'])\n",
    "    print(\"\\n4. Sau khi label encode:\")\n",
    "    print(df_encoded)\n",
    "    print(\"Mapping:\", mapping)\n",
    "    \n",
    "    # Test chuẩn hóa\n",
    "    scaler = StandardScaler()\n",
    "    numeric_cols = ['age', 'salary', 'experience']\n",
    "    df_numeric = df_encoded[numeric_cols]\n",
    "    df_scaled = scaler.fit_transform(df_numeric)\n",
    "    print(\"\\n5. Sau khi standard scaling:\")\n",
    "    print(df_scaled)\n",
    "    \n",
    "    # Test split train/test\n",
    "    y = np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_scaled, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    print(\"\\n6. Kết quả split:\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    \n",
    "    # Test pipeline\n",
    "    pipeline = DataPipeline()\n",
    "    X_processed = pipeline.fit(df, \n",
    "                              normalize=True,\n",
    "                              scale_method='standard',\n",
    "                              handle_missing=True,\n",
    "                              missing_strategy='mean',\n",
    "                              encode_categorical=True,\n",
    "                              encode_method='label')\n",
    "    print(\"\\n7. Kết quả pipeline:\")\n",
    "    print(X_processed.head())\n",
    "    \n",
    "    print(\"\\nKIỂM TRA HOÀN TẤT!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_library()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33391456-7aa0-497e-a42b-990ca075ddbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
